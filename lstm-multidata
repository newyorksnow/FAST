# ============================================ CONTROLLED RANDOMNESS FOR REPRODUCIBILITY
import random
import numpy as np
import os
import tensorflow as tf

SEED = 43  #vary. in this experiment: 1-9 and 43 were used

#set randomness ofr python, numpy, tensorflow and python hashing
random.seed(SEED)
np.random.seed(SEED)
os.environ['PYTHONHASHSEED'] = str(SEED)
tf.random.set_seed(SEED)  #controls tensorflow random operations (weight initialization, dropout, etc.)

os.environ['TF_DETERMINISTIC_OPS'] = '1'  #forces deterministic operations
os.environ['TF_CUDNN_DETERMINISTIC'] = '1'  #forces deterministic cuDNN operations

# ====================================================== DATA SORTING/DROPPING/FILTERING
import pandas as pd
from sklearn.preprocessing import MinMaxScaler
from sklearn.preprocessing import LabelEncoder
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Masking
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.callbacks import EarlyStopping
from sklearn.metrics import (
    accuracy_score,
    precision_score,
    recall_score,
    log_loss,
    confusion_matrix,
    f1_score,
    roc_auc_score 
)
from sklearn.utils.class_weight import compute_class_weight
from sklearn.model_selection import train_test_split
import json


data = pd.read_csv("/home/user/Downloads/workspace/combined_data.csv")

# ============================================ FIXING DATA TYPE ISSUES

# convert str to numeric in h cols
h = ["A_gni", "B_gdp_per_capita"]

#apply 
for col in h:
    data[col] = (
        data[col]
        .astype(str)
        .str.replace(",", "", regex=False)   # literal comma
        .str.strip()
        .replace({"..": np.nan, "NA": np.nan})
    )
    data[col] = pd.to_numeric(data[col], errors="coerce")

# ------------- FIXING DATA TYPE PROBLEMS IN COLS

# FIX STR IN F_SUCCESS
data = data[~data["F_success"].str.contains("Insurgency/Guerilla Action", na=False)].copy()
data["F_success"] = pd.to_numeric(data["F_success"], errors="coerce")

# FOR F_TARGTYPE1
data = data[~data["F_targtype1"].str.contains("Facility/Infrastructure Attack", na=False)].copy()
data["F_targtype1"] = pd.to_numeric(data["F_targtype1"], errors="coerce")
data = data.dropna(subset=["F_targtype1"]).copy()

#WEAPTYPE1
data = data[~data["F_weaptype1"].str.contains("Posted to website, blog, etc.", na=False)].copy()
data["F_weaptype1"] = pd.to_numeric(data["F_weaptype1"], errors="coerce")

#resetting index after filtering/cleaning to ensure proper alignment in 'data'
data = data.reset_index(drop=True)

# =============================================================== DATA PREPROCESSING                                                                ******

#70% training, 15% validation, 15% test
train_end = int(0.7 * len(data))
val_end = int(0.85 * len(data))

train_data = data.iloc[:train_end]
val_data = data.iloc[train_end:val_end]
test_data = data.iloc[val_end:]

# ------------------------ SCALING TRAINING DATA


scaler = MinMaxScaler()

#excluding Year and targets from scaling (targets shouldn't be scaled)
num_cols = [
    col for col in data.columns
    if col not in ["iso3", "Year", "F_success"] and data[col].dtype != "object"
]

# replace -1 with NaN temporarily for scaling (so -1 doesn't get lost in the scaling process)
for col in num_cols:
    train_data[col] = train_data[col].replace(-1, np.nan)
    val_data[col] = val_data[col].replace(-1, np.nan)
    test_data[col] = test_data[col].replace(-1, np.nan)

# fit scaler only on non-NaN values
train_data[num_cols] = scaler.fit_transform(train_data[num_cols])

# apply the same transformation to validation and test sets
val_data[num_cols] = scaler.transform(val_data[num_cols])
test_data[num_cols] = scaler.transform(test_data[num_cols])

# replace NaN back with -1 after scaling (for masking in LSTM)
for col in num_cols:
    train_data[col] = train_data[col].fillna(-1)
    val_data[col] = val_data[col].fillna(-1)
    test_data[col] = test_data[col].fillna(-1)


# ----------------------------------------------------- TARGET VARIABLES

#------binary target (F_success)
y_f_success_train = train_data["F_success"].values.astype(float)
y_f_success_val = val_data["F_success"].values.astype(float)
y_f_success_test = test_data["F_success"].values.astype(float)

#------categorical target (iso3 country code)

# first must convert country codes to integers using labelencode
le = LabelEncoder()

y_iso3_train = le.fit_transform(train_data["iso3"]) #apply
y_iso3_val = le.transform(val_data["iso3"])
y_iso3_test = le.transform(test_data["iso3"])

#number of unique countries (how many classes there are)
num_countries = len(le.classes_)

#custom loss function needs integers, so not hotencoding

# -------------------------------------------------- SELECTING FEATURES (INPUT/ X) + BUILDING SEQUENCES

# only exclude target variables, preserve all other features
feature_cols = [
    col for col in data.columns
    if col not in ["iso3", "Year", "F_success"]
]

# The LSTM looks at the last few time steps (events/rows)
sequence_length = 5

#build sequences PER COUNTRY to avoid mixing different countries in one sequence
def build_sequences(df, y_f, y_i):

    X, Yf, Yi = [], [], []

    iso3_values = df["iso3"].values  # country for each row
    features_data = df[feature_cols].values.astype(float)  # selected feature data as float

    # group row indices by country so sequences stay inside one country (prevents leakage)
    country_indices = {}
    for idx, iso3_code in enumerate(iso3_values):
        country_indices.setdefault(iso3_code, []).append(idx)

    for _, idx_list in country_indices.items():
        idx_list = sorted(idx_list)  # keep time order within country
        if len(idx_list) < sequence_length + 1:  # skip very short histories
            continue
        for i in range(len(idx_list) - sequence_length):
            seq_idx = idx_list[i : i + sequence_length]  # indices for the input window
            target_idx = idx_list[i + sequence_length]   # index for the prediction target
            X.append(features_data[seq_idx])
            Yf.append(y_f[target_idx])
            Yi.append(y_i[target_idx])

    return np.array(X), np.array(Yf), np.array(Yi)


#build sequences for training, validating and testing
X_train, Yf_train, Yi_train = build_sequences(
    train_data, y_f_success_train, y_iso3_train
)

X_val, Yf_val, Yi_val = build_sequences(
    val_data, y_f_success_val, y_iso3_val
)

X_test, Yf_test, Yi_test = build_sequences(
    test_data, y_f_success_test, y_iso3_test
)

# ========================================================================================================= LSTM ARCHITECTURE

# Input sequence shape:(sequence_length, number_of_features)
inputs = Input(shape=(X_train.shape[1], X_train.shape[2]))

#MASKING F_success -1 VALUES (NaN placeholders shouldn't be seen as signal by the model)
masked_inputs = Masking(mask_value=-1.0)(inputs)

# shared LSTM layer (64 units to handle both temporal patterns and geographic signatures)
shared = LSTM(64)(masked_inputs)

# ----------------------------------- HEAD 1: BINARY "SUCCESS"
f_success_out = Dense( #(output layer name)
    1,
    activation="sigmoid",
    name="f_success"
)(shared)

# ---------------------------------- HEAD 2: CATEGORICAL "ISO3"
iso3_out = Dense( #(output layer name)
    num_countries,
    activation="softmax",
    name="iso3"
)(shared)

# create model
model = Model(
    inputs=inputs,
    outputs=[f_success_out, iso3_out]
)

#===================================================== APPLYING CLASS WEIGHTS

#"class_weights" parameter not applicable to multioutput, must make own loss function:


y_f_success_train_mask = y_f_success_train[y_f_success_train != -1]  #exclude masked -1 (NaNs) bc they aren't a real class

#CATEGORICAL TARGET: creates weights for minority/majority "compute_class_weight"
f_success_class_weights = dict(enumerate(compute_class_weight('balanced', classes=np.arange(2), y=y_f_success_train_mask)))
if y_iso3_train.ndim == 2:
    y_iso3_labels = np.argmax(y_iso3_train, axis=1)
else:
    y_iso3_labels = y_iso3_train  # already integer labels
iso3_class_weights = dict(enumerate(compute_class_weight('balanced', classes=np.arange(num_countries), y=y_iso3_labels)))

#align weights with labelencoder alphabetical order (AFG=0, ALB=1, ... ZWE=185 so on)
country_weights = tf.constant(
    [iso3_class_weights[i] for i in range(num_countries)],  # index i matches LabelEncoder's integer label i
    dtype=tf.float32
)

#BIANRY TARGET: convert the python dictionaries into tensors so they can be used inside tensorflow loss functions
pos_weight = tf.constant(
    f_success_class_weights[0] / f_success_class_weights[1],  # this ratio between minority and majority class weights is > 1 and multiplied with loss
    dtype=tf.float32
)

# ----------------------- binary loss function(F_success)                                                                                                       ****
def binary_loss(y_true, y_pred):

    #filter out -1
    mask = tf.not_equal(y_true, -1)

    #keep only valid samples
    y_true = tf.boolean_mask(y_true, mask)
    y_pred = tf.boolean_mask(y_pred, mask)

    #function (with logits)
    loss = tf.keras.losses.binary_crossentropy(y_true, y_pred)
    
    #apply class weights: minority class (0) gets pos_weight, majority class (1) gets 1.0
    # ==  should upweight the loss when true label is 0 (minority)
    weights = tf.where(tf.equal(y_true, 0), pos_weight, 1.0)

    return tf.reduce_mean(loss * weights)


#----------------- categorical loss function (countries)
def country_loss(y_true, y_pred):
    """
    Weighted sparse categorical cross-entropy.

    - y_true contains integer country IDs
    - Rare countries receive larger penalties
    - Works with logits (no softmax required in model)
    """

    #ensure correct dtype of "iso3" (int32)
    y_true = tf.cast(y_true, tf.int32)

    #cross-entropy function (per-sample)
    ce = tf.keras.losses.sparse_categorical_crossentropy(
        y_true, y_pred, from_logits=False
    )

    #look up weight for each true country (see above)
    weights = tf.gather(country_weights, y_true)

    #apply class weights
    return tf.reduce_mean(ce * weights)

# ================================================================================================= COMPILE  

model.compile(
    optimizer="adam",
    metrics={
        "f_success": "accuracy",
        "iso3": "accuracy",
    },
     loss = { "f_success": binary_loss, "iso3": country_loss },  # apply custom loss function (class_weight paramter substiute)
)

print("shape:", y_f_success_train)

# ---------------------------------------- TRAIN

model.summary()

model.fit(
    X_train,
    {
        "f_success": Yf_train,
        "iso3": Yi_train
    },
    validation_data=(
        X_val,
        {
            "f_success": Yf_val,
            "iso3": Yi_val
        },
    ),
    epochs=20,
    batch_size=32,
    callbacks=[EarlyStopping(monitor='val_loss', patience=5)]  # stops early if no improvement in val loss for 5 epochs
)

# ------------------------------------------------------ PRINTING PREDICTIONS

pred_f_success, pred_iso3 = model.predict(X_test)

print("\nSample F_success predictions (probabilities):")
for i in range(120):
    print(f"{i}: {pred_f_success[i][0]:.4f}")

pred_iso3_labels = le.inverse_transform(
    np.argmax(pred_iso3, axis=1)
)

print("\nSample iso3 predictions:")
for i in range(120):
    print(f"{i}: {pred_iso3_labels[i]}")

# ============================================================================================================ EVALUATION (METRICS)

# success:
mask = Yf_test != -1 #exclude -1 from metrics: impossible to know its value

y_true_success = Yf_test[mask].astype(int) #the model predictions
y_pred_success_proba = pred_f_success.flatten()[mask] #the actual values
y_pred_success = (y_pred_success_proba >= 0.5).astype(int) #threshold=0.5 to convert probabilities to binary labels

# ============================================ COMPUTE METRICS

# F_success metrics
f_acc = accuracy_score(y_true_success, y_pred_success)
f_prec = precision_score(y_true_success, y_pred_success, zero_division=0)
f_rec = recall_score(y_true_success, y_pred_success, zero_division=0)
f_f1 = f1_score(y_true_success, y_pred_success, zero_division=0)
f_logloss = log_loss(y_true_success, y_pred_success_proba)
f_auc = roc_auc_score(y_true_success, y_pred_success_proba) #a.k.a threshold-independent performance
f_cm = confusion_matrix(y_true_success, y_pred_success)

#print metrics f_success
print("\n" + "="*60)
print("F_SUCCESS METRICS (Binary Classification)")
print("="*60)
print(f"Accuracy:           {f_acc:.4f}  ({f_acc*100:.2f}%)")
print(f"Precision:          {f_prec:.4f}  (of predicted positives, how many are correct)")
print(f"Recall:             {f_rec:.4f}  (of actual positives, how many caught)")
print(f"F1-Score:           {f_f1:.4f}  (harmonic mean of precision & recall)")
print(f"AUC-ROC:            {f_auc:.4f}  (area under ROC curve, 0.5=random, 1.0=perfect)")
print(f"Log Loss:           {f_logloss:.4f}  (lower is better, measures calibration)")
print(f"\nConfusion Matrix:")
print(f"                    Predicted")
print(f"                    Neg    Pos")
print(f"Actual Neg     [[{f_cm[0][0]:6d} {f_cm[0][1]:6d}]]")
print(f"Actual Pos     [[{f_cm[1][0]:6d} {f_cm[1][1]:6d}]]")
print(f"\nInterpretation:")
print(f"  True Negatives (TN):  {f_cm[0][0]:6d}  (correctly predicted negative)")
print(f"  False Positives (FP): {f_cm[0][1]:6d}  (wrongly predicted positive)")
print(f"  False Negatives (FN): {f_cm[1][0]:6d}  (wrongly predicted negative)")
print(f"  True Positives (TP):  {f_cm[1][1]:6d}  (correctly predicted positive)")

# iso3 metrics:
y_true_iso3 = Yi_test  # turn probabilities into processable labels
y_pred_iso3 = np.argmax(pred_iso3, axis=1)

iso_acc = accuracy_score(y_true_iso3, y_pred_iso3)
iso_prec_macro = precision_score(y_true_iso3, y_pred_iso3, average="macro", zero_division=0)
iso_rec_macro = recall_score(y_true_iso3, y_pred_iso3, average="macro", zero_division=0)
iso_f1_macro = f1_score(y_true_iso3, y_pred_iso3, average="macro", zero_division=0)

labels = np.arange(pred_iso3.shape[1])  # [0, 1, 2, ..., 185]
iso_logloss = log_loss(y_true_iso3, pred_iso3, labels=labels)
iso_cm = confusion_matrix(y_true_iso3, y_pred_iso3)

# top-5 accuracy
top5_correct = 0
for i in range(len(y_true_iso3)):
    top5_preds = np.argsort(pred_iso3[i])[-5:]  # indices of top 5 predictions
    if y_true_iso3[i] in top5_preds:
        top5_correct += 1
iso_top5_acc = top5_correct / len(y_true_iso3)

#print metrics iso3
print("\n" + "="*60)
print("ISO3 METRICS (Multiclass Classification - 186 Countries)")
print("="*60)
print(f"Accuracy:           {iso_acc:.4f}  ({iso_acc*100:.2f}%)")
print(f"Top-5 Accuracy:     {iso_top5_acc:.4f}  ({iso_top5_acc*100:.2f}%)  (correct country in top 5 predictions)")
print(f"Macro Precision:    {iso_prec_macro:.4f}  (average across all 186 countries)")
print(f"Macro Recall:       {iso_rec_macro:.4f}  (equal weight to rare & common countries)")
print(f"Macro F1-Score:     {iso_f1_macro:.4f}  (harmonic mean, balanced metric)")
print(f"Log Loss:           {iso_logloss:.4f}  (lower is better, measures calibration)")
print(f"\nConfusion Matrix: {iso_cm.shape[0]}x{iso_cm.shape[1]} (too large to print)")
print(f"  - Diagonal sum (correct): {np.trace(iso_cm)}")
print(f"  - Off-diagonal sum (errors): {iso_cm.sum() - np.trace(iso_cm)}")

print("validation of splits")
print("Train data shape", X_train.shape)
print("Validation data shape", X_val.shape)
print("Test data shape", X_test.shape)


#------------------------------------------------------saving

# Compute metrics dictionary for CSV export (if desired)
metrics = {
    "f_success": {
        "accuracy": f_acc,
        "precision": f_prec,
        "recall": f_rec,
        "f1_score": f_f1,
        "auc_roc": f_auc,
        "log_loss": f_logloss,
        "confusion_matrix": f_cm.tolist()
    },
    "iso3": {
        "accuracy": iso_acc,
        "top5_accuracy": iso_top5_acc,
        "precision_macro": iso_prec_macro,
        "recall_macro": iso_rec_macro,
        "f1_score_macro": iso_f1_macro,
        "log_loss": iso_logloss,
        "confusion_matrix": iso_cm.tolist()
    }
}

#seed information and summary
print("\n" + "="*60)
print("EXPERIMENT CONFIGURATION")
print("="*60)
print(f"Random Seed:        {SEED}")
print(f"Train samples:      {X_train.shape[0]} sequences")
print(f"Validation samples: {X_val.shape[0]} sequences")
print(f"Test samples:       {X_test.shape[0]} sequences")
print(f"Sequence length:    {X_train.shape[1]} time steps")
print(f"Features per step:  {X_train.shape[2]} features")
print(f"\nNote: For scientific comparison, run this script multiple times")
print(f"with different seeds (e.g., SEED=0,1,2,...,9) and compute:")
print(f"  - Mean Â± Std for each metric")
print(f"  - 95% confidence intervals")
print(f"  - Statistical significance tests (paired t-test)")
print(f"\nSee SCIENTIFIC_COMPARISON_GUIDE.md for detailed instructions.")